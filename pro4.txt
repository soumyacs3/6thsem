'''
Program 4: 
Use word embeddings to improve prompts for Generative AI model. Retrieve similar words using word embeddings. Use the similar words to enrich a GenAI prompt. Use the AI model to generate responses for the original and enriched prompts. Compare the outputs in terms of detail and relevance. 
Theory: 
This program demonstrates how word embeddings can be used to improve Generative AI responses by replacing specific words in a prompt with their most semantically similar words. The enriched prompt is then compared with the original prompt in terms of response detail and relevance. 
The program utilizes three main concepts: 1.1 Word Embeddings (GloVe) 
Word embeddings convert words into vector representations such that similar words have closer vector distances in the embedding space. 
The model glove-wiki-gigaword-100 provides 100-dimensional word vectors pre-trained on Wikipedia and Gigaword data. 
1.2 Generative AI Model (GPT-2) 
GPT-2 (a Transformer-based model) is a Generative AI model capable of autocompleting text. 
It predicts the next word in a sequence based on context. The model is pre-trained on large internet-based datasets. It generates text using context from the input prompt.
1.3 Prompt Enrichment with Word2Vec 
The program replaces a user-defined keyword with its most semantically similar word (found using word embeddings). 
This helps enhance the prompt and produce a more detailed and meaningful AI-generated response. 
Steps Involved in Execution
Step 1: Import Necessary Libraries
gensim.downloader ‚Üí Loads pre-trained word embeddings (GloVe). transformers.pipeline ‚Üí Loads GPT-2 model for text generation. 
nltk.tokenize.word_tokenize ‚Üí Tokenizes the prompt for word replacement. 
Step 2: Load Pre-Trained Word Vectors
Downloads and loads the GloVe 100-dimensional embeddings. These embeddings contain semantic relationships between words. Step 3: Replace a Keyword with Its Most Similar Word
Function Breakdown 
Tokenizes the prompt into words.
Finds the most similar word to the user-specified keyword. Replaces the keyword with the similar word (if found). Constructs an enriched prompt with the modified word. Load GPT-2 Model for Text Generation
Loads GPT-2 from the transformers library.
Creates a text-generation pipeline for generating responses 
Step 5:
Function Breakdown 
asses the prompt to GPT-2 for text generation.
Returns the AI-generated response.
Define the Original Prompt
This is the input query that the AI model will respond to. Retrieve a Similar Word for the Keyword 
User specifies the keyword "king".
The function retrieves a semantically similar word (e.g., "monarch").
Generate AI Responses for Both Prompts
GPT-2 generates responses for both the original and enriched prompts.
The enriched prompt provides more meaningful output due to better word choice. Compare the Generated Outputs
Compares length and detail of both responses.
More details (more sentences) indicate a richer response. 
‚úÖ Improved Prompt Quality ‚Üí Semantic word replacement enhances the prompt.
‚úÖ Better AI Responses ‚Üí GPT-2 generates more meaningful responses with an enriched 
prompt. 
‚úÖ Word Embeddings Integration ‚Üí Uses GloVe to find semantically similar words. 
‚úÖ Comparison of Outputs ‚Üí Measures improvement using response length and detail. 

'''
!pip install gensim transformers --quiet

import gensim.downloader as api
from transformers import pipeline
import nltk
import string
from nltk.tokenize import word_tokenize

# Download necessary NLTK resources
nltk.download('punkt')
nltk.download('punkt_tab')

# Load pre-trained word vectors
print("üîπ Loading pre-trained word vectors...")
word_vectors = api.load("glove-wiki-gigaword-100")  # 100-dimensional GloVe vectors

# Function to replace a keyword with a similar word
def replace_keyword_in_prompt(prompt, keyword, word_vectors, topn=1):
    words = word_tokenize(prompt)
    enriched_words = []

    for word in words:
        cleaned_word = word.lower().strip(string.punctuation)
        if cleaned_word == keyword.lower():
            try:
                similar_words = word_vectors.most_similar(cleaned_word, topn=topn)
                if similar_words:
                    replacement_word = similar_words[0][0]
                    print(f"üîÅ Replacing '{word}' ‚Üí '{replacement_word}'")
                    enriched_words.append(replacement_word)
                    continue
            except KeyError:
                print(f"‚ö†Ô∏è '{keyword}' not found in the vocabulary. Using original word.")
        enriched_words.append(word)

    enriched_prompt = " ".join(enriched_words)
    print(f"\nüîπ Enriched Prompt: {enriched_prompt}")
    return enriched_prompt

# Load GPT-2 text generation model
print("\nüß† Loading GPT-2 model...")
generator = pipeline("text-generation", model="gpt2")

# Generate a text response
def generate_response(prompt, max_length=100):
    try:
        response = generator(prompt, max_length=max_length, num_return_sequences=1)
        return response[0]['generated_text']
    except Exception as e:
        print(f"Error generating response: {e}")
        return None

# Example run
original_prompt = "Who is king."
print(f"\nüîπ Original Prompt: {original_prompt}")
key_term = "king"

# Enrich and generate responses
enriched_prompt = replace_keyword_in_prompt(original_prompt, key_term, word_vectors)

print("\nüí¨ Generating response for original prompt...")
original_response = generate_response(original_prompt)
print("\nOriginal Response:\n", original_response)

print("\nüí¨ Generating response for enriched prompt...")
enriched_response = generate_response(enriched_prompt)
print("\nEnriched Response:\n", enriched_response)

# Compare
print("\nüìä Comparison:")
print("Original Length:", len(original_response))
print("Enriched Length:", len(enriched_response))
print("Original Sentences:", original_response.count("."))
print("Enriched Sentences:", enriched_response.count("."))


'''
=====================
Output: 
[nltk_data] Downloading package punkt to /root/nltk_data... [nltk_data] Package punkt is already up-to-date!
Loading pre-trained word vectors...
Loading GPT-2 model... 
Device set to use cpu 
Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`. 
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation. 
üîπ Original Prompt: Who is king. Replacing 'king' ‚Üí 'prince'
üîπ Enriched Prompt: Who is prince . 
Generating response for the original prompt...
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation 
Original Prompt Response: 
Who is king. Is any one of them a son of God? He is the Lord of every kingdom. (3)--But, in the case of the Son of Man there was seen: how much is it with us to know that he is the Son of God? Now I am in an immolated body so that you could look with a clear eye at the Scriptures. And I was told by a man whom I know not whom you will come out, that the Lord had his own daughter 
Generating response for the enriched prompt... 
Enriched Prompt Response: 
Who is prince ...?" 
And this prince is one of the lords of the earth and of the kings of the world? The God of his Kingdom. 
He was an uncle who was named by God and was taken away by men for the adultery of some of them who had gone before him. 
And what is a prince? 
One who is Prince of heaven and of the earth, like him who comes to me with water in one hand and his Lord with 
Comparison of Responses: 
Original Prompt Response Length: 380 Enriched Prompt Response Length: 382 
Original Prompt Response Detail: 3 Enriched Prompt Response Detail: 5 
'''
